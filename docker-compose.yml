
services: 
  kafka1:
    image: confluentinc/cp-kafka:latest
    container_name: kafka1
    restart: always
    ports:
      - "9094:9094"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_LISTENERS: PLAINTEXT://kafka1:29092,CONTROLLER://kafka1:29093,PLAINTEXT_HOST://0.0.0.0:9094
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka1:29092,PLAINTEXT_HOST://172.168.110.205:9094
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka1:29093'
      KAFKA_LOG_DIRS: '/tmp/kraft-combined-logs'
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'
      # Settings to prevent duplicate messages
      KAFKA_ENABLE_IDEMPOTENCE: 'true'
      KAFKA_MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION: 5
      KAFKA_ACKS: 'all'
      KAFKA_RETRIES: 2147483647
      KAFKA_REQUEST_TIMEOUT_MS: 300000
      KAFKA_DELIVERY_TIMEOUT_MS: 600000
    volumes:
      - ./kafka1-data:/tmp/kraft-combined-logs

  kafdrop:
    image: obsidiandynamics/kafdrop:latest
    container_name: kafdrop
    restart: always
    ports:
      - "9000:9000"
    environment:
      KAFKA_BROKERCONNECT: "kafka1:29092"
      JVM_OPTS: "-Xms64M -Xmx128M"  # Increased memory
      SERVER_SERVLET_CONTEXTPATH: "/"
      KAFKA_PROPERTIES: "fetch.message.max.bytes=50000000"
      CMD_ARGS: "--message.format=DEFAULT"
    depends_on:
      - kafka1

networks:
  default:
    driver: bridge